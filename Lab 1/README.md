

# Staging Interaction

In the original stage production of Peter Pan, Tinker Bell was represented by a darting light created by a small handheld mirror off-stage, reflecting a little circle of light from a powerful lamp. Tinkerbell communicates her presence through this light to the other characters. See more info [here](https://en.wikipedia.org/wiki/Tinker_Bell). 

There is no actor that plays Tinkerbell--her existence in the play comes from the interactions that the other characters have with her.

For lab this week, we draw on this and other inspirations from theatre to stage interactions with a device where the main mode of display/output for the interactive device you are designing is lighting. You will plot the interaction with a storyboard, and use your computer and a smartphone to experiment with what the interactions will look and feel like. 

_Make sure you read all the instructions and understand the whole of the laboratory activity before starting!_

## Lab Overview
For this assignment, you are going to:

A) [Plan](#part-a-plan) 

B) [Act out the interaction](#part-b-act-out-the-interaction) 

C) [Prototype the device](#part-c-prototype-the-device)

D) [Wizard the device](#part-d-wizard-the-device) 

E) [Costume the device](#part-e-costume-the-device)

F) [Record the interaction](#part-f-record)

Labs are due on Mondays. Make sure this page is linked to on your main class hub page.

## Part A. Plan 

_Intro:_ 

In this digital world, especially during the pandemic, people are always working from home and keeping social distance from each other. When we're sitting next to each other, people can detect others' emotion or moods by subtle body hints. But now we are apart, it's hard to detect our loved ones' subtle emotion swings and we probably do not feel the necessity to say that "I am feeling slightly upset/delighted because of …". In addition, in this busy era we may not find time to always be on video calls or chats, so is there an easy way to feel you're companied, heard and felt by your loved ones?

By using the tinkerbelle interactive device, people can indicate their moods simply by adjusting color on their device and whoever has access to their tinkerbelle will be able to see their mood color instantly. 

_Setting:_ 

The interaction can happen at any place between 2 people A and B who are physically apart (it can also happen when they are being next to each other but then lose the point of using this interaction). Each individual can both receive and send a "signal". A signal you receive reflects the other person's mood, and the signal you send out reflects your own mood. !

_Players:_ 

In each interaction, a limited number of individuals are involved. One signaler can send signal to a maximum of 5 people at the same time. There may be other people that's around these participants who can see/hear the signal. 

_Activity:_ 

The signal sender can change the color which reflects their mood and the receiver will see the color changed on their side. 

_Goals:_ 

There are two goals for each player, depends on their own purpose.
  - Goal 1: to showcase their own mood to the others, so that they feel being heard and felt
  - Goal 2: to react to the other's mood, so that they can provide comfort/understanding/resonance to the other's mood !


The interactive device can be anything *except* a computer, a tablet computer or a smart phone, but the main way it interacts needs to be using light.

\*\***Include a picture of your storyboard here**\*\*

![IMG_5743](https://user-images.githubusercontent.com/89592832/132149347-dc8c4a5d-f66f-4995-8110-9c2383bfa453.JPG)


\*\***Summarize feedback you got here.**\*\*

The original idea was to design the device to be a key chain so that the player can carry it around. However, the small size of a key chain may add complication to the device since it also needs to have a color selection panel and mute/unmute buttom. So I later modified it to be a lamp that can be placed on a desk/table. 
Updated story board: 
![IMG_5741](https://user-images.githubusercontent.com/89592832/132148062-1737a613-f791-4adc-8608-5bbcb359125c.JPG)


## Part B. Act out the Interaction

Try physically acting out the interaction you planned. For now, you can just pretend the device is doing the things you’ve scripted for it. 

\*\***Are there things that seemed better on paper than acted out?**\*\*

The interaction seems more "interactive" when it's on paper. In reality it might be too easy to be ignored if the signal receiver is not paying attention to the device. 
Also it remains a question how to connect two devices when they are apart. 

\*\***Are there new ideas that occur to you or your collaborators that come up from the acting?**\*\*

I would need to put a mute/unmute button on the device so it doesn't play in unwanted situation. Also what's a smart way to change your own light on the other side, without having to open an app on your mobile phone? I thought to add the color selection panel onto the device. 

## Part C. Prototype the device

You will be using your smartphone as a stand-in for the device you are prototyping. You will use the browser of your smart phone to act as a “light” and use a remote control interface to remotely change the light on that device. 

Code for the "Tinkerbelle" tool, and instructions for setting up the server and your phone are [here](https://github.com/FAR-Lab/tinkerbelle).

We invented this tool for this lab! 

If you run into technical issues with this tool, you can also use a light switch, dimmer, etc. that you can can manually or remotely control.

\*\***Give us feedback on Tinkerbelle.**\*\*

When using one device to control multiple devices to play sound, the sound doesn't start at the same time on all devices and thus creating an echo sound. I'm not sure if that's due to internet speed on different devices or other reasons. It would be nice if they can be perfectly synchronized at the same time. 

## Part D. Wizard the device
Take a little time to set up the wizarding set-up that allows for someone to remotely control the device while someone acts with it. Hint: You can use Zoom to record videos, and you can pin someone’s video feed if that is the scene which you want to record. 

\*\***Include your first attempts at recording the set-up video here.**\*\*

The idea is that two players, Anna and Bella, each has their own device A and B. Consider each device as a lamp with color selection board. Player Anna can select a color, say green, on device A, so that device B will turn green. If Bella selects red on device B, then device A will become red. 

First attempt recording:[Google drive link](https://drive.google.com/file/d/1b3B-7mOH2Vnm0u__Av7LjcLlsZtXFdu8/view?usp=sharing)

Follow-up work recording: [Google drive link](https://drive.google.com/file/d/1awIFTGxpL2P1AZYKmwD0wtEDGBO9qpij/view?usp=sharing)


## Part E. Costume the device

_Only now should you start worrying about what the device should look like. Develop a costume so that you can use your phone as this device.

Think about the setting of the device: is the environment a place where the device could overheat? Is water a danger? Does it need to have bright colors in an emergency setting?_

\*\***Include sketches of what your device might look like here.**\*\*

![IDD lab1 tinkerbelle device](https://user-images.githubusercontent.com/89592832/132148756-f77ac693-a12a-4438-a353-cdfa26b4ab04.JPG)

\*\***What concerns or opportunitities are influencing the way you've designed the device to look?**\*\*

The device would need a color selection board, a mute/unmute button and a light bulb. So the beta version is relatively big as a lamp. I also want it to have a rounded shape and dimmed light to provide a feeling of embracing and soothing. 

## Part F. Record

Recording of prototyped interaction: [Google Drive link](https://drive.google.com/file/d/1OGTxBszlh5Uili7OczxNBhn5yLUny6nI/view?usp=sharing)

_Story behind the scene:_ 
I was back at home while doing this project so my mother helped me to demonstrate in the video. She also inspired me to have this idea at the first place as we don't have time to chat all the time but we want to know how the other is doing in another city/timezone. 

I am also inspired by a Play Station game called _Journey_. In this game, the player will be playing all alone in the very wide world setting. Along the way the player can meet another individual player and continue the journey together, but the two cannot communicate via speech or text and cannot see each other's names. The only form of communication between the two is a musical chime. It is amazing how much comfort and pleasure a simple format of non-verbal communication can bring.



# Staging Interaction, Part 2 

This describes the second week's work for this lab activity.


## Prep 

**Feedback:**

I received three feedbacks from Andrew Scibell, Matthew Ardizzone and Robert Aaron Konigsberg. Their feedback included:
1. Body language and emotional expression are somewhat involuntary so I wish the color selection had an automated option as well, some way of detecting the user's emotional state without an input. 
2. Should be a way for the other person to know if your device is muted. 
3. Flash the other person's light is like a mood-flashing pager. 
4. Sometimes we may not want to know who we are talking to.
5. The non-instrusive communication aspect is good. Will user remember who was the last one to update the color?
6. Specify the audio. 


**Brainstorming:**

Based on the feedbacks, here are some new ideas I'd like to apply:
1. Automated color selection: It's a great idea to make color change/selection automated since the time when we need other's support may also be the time we do not want to express ourselves (ie. angry, sad etc.). Several ways for the device to be able to detect user's mood and change color automatically:

  a. Detect body movement. Fast movement = rush = red, moderate movement = occupied = yellow, very slow movement = chill = blue etc. Problem is that the same body movement speed may indicate totally different moods. 
  
  b. Detect body conditions including body temperature, heart beat etc. This would require the user to wear the device, like an Apple watch. 
  
  c. Detect sound volume around. But similar to the first point, it may be hard to determine what the true mood is solely based on sound volume. 
  
2. The small area around the muted button should also be lighted. A bright color means it's unmuted on the other side and a dark color means the other user has muted their device. 

3. There will only be a limited number of audios (less than 10) for user to choose. Audio will not be very specific (not a happy birthday song), but instead short piece of music/sound that vaguely convey a mood/feeling. 


**Plan:**

1. Change the device from a lamp to a watch/bracelet/necklace, something that the user can wear for the device to detect body temperature/heartbeat/level of sweat. 
2. Add a auto-mode switch button. The user can choose either they want the device to automatically change colors on the other side, or to manually change the color by themselves. 
3. Set a matrix for color automation. For example, low temperature+high heartbeat+sweat may indicates the wearer is frustrated, so a purple color will show on the other side. Or a high temperature+high heartbeat+no sweat may indicates the wearer is excited, so a orange color will show. 
4. Add color to the muted button. 
5. Add audio selection option. 
  
 
**Prototype Design:**

There will be two players involved: the wearer and the recipient. Each player will wear their own device and send signal to change color/audio for the other player. 

<img width="464" alt="Screen Shot 2021-09-13 at 12 57 29 PM" src="https://user-images.githubusercontent.com/89592832/133125722-4aabff69-a242-4508-ba48-eff2b7b7e33e.png">
<img width="476" alt="Screen Shot 2021-09-13 at 12 57 40 PM" src="https://user-images.githubusercontent.com/89592832/133125731-4196b31a-987d-44bd-8f6f-5ea8043da5c0.png">
<img width="677" alt="Screen Shot 2021-09-13 at 12 57 47 PM" src="https://user-images.githubusercontent.com/89592832/133125743-99b605a8-9874-4fcb-8c9b-53cd84ae0fbf.png">

Video:
https://drive.google.com/file/d/1iNv8zjdIlch1lxhNV_aa-YTJ_SiG4i6Q/view?usp=sharing

## Make it your own

Do last week’s assignment again, but this time: 
1) It doesn’t have to (just) use light, 
2) You can use any modality (e.g., vibration, sound) to prototype the behaviors! Again, be creative!
3) We will be grading with an emphasis on creativity. 

\*\***Document everything here. (Particularly, we would like to see the storyboard and video, although photos of the prototype are also great.)**\*\*
